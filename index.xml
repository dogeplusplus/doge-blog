<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>dogeplusplus</title><link>https://dogeplusplus.github.io/</link><description>Recent content on dogeplusplus</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Mon, 14 Nov 2022 00:00:00 +0100</lastBuildDate><atom:link href="https://dogeplusplus.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Equivariance Properties in Machine Learning</title><link>https://dogeplusplus.github.io/posts/equivariance/</link><pubDate>Mon, 14 Nov 2022 00:00:00 +0100</pubDate><guid>https://dogeplusplus.github.io/posts/equivariance/</guid><description>Introduction When we think about the signs for what is a good model, we first look to notions of accuracy, precision, recall and the like. Evaluating these metrics typically require a ground truth to evaluate against, and is rarely the case that a machine learning practitioner will not have at least a few examples to test on.
In medical imaging deep learning is applied to make measurements about our bodies such as organ size, which helps us gain understand our health.</description></item></channel></rss>